http://hortonworks.com/hadoop-tutorial/how-to-process-data-with-apache-pig/
Same example using pig
****************************************************************************
Thursday, November 13, 2014 12:34 AM
Section 3/14
http://hortonworks.com/hadoop-tutorial/how-to-process-data-with-apache-hive/

->How to Process Data with Hive using a set of Baseball statistics on American players from 1871-2011.
Apache Hive Video

What is Hive?
	DWH  layer 
	HiveQL  - adhoc que, summarisation and Data Analysis
	Used for WebLogs
	Not a RDBMS
	Not Online transaction Processing .Only Batch
	Poly Structured data

UDF..No of rows  to a single row.

Hive vs Pig
	To query  data
	answer specific question
	familiar with sql
Pig;
	Preparing for Easier analysis
	data objects only exist inside the script, unless they  are stored	
	
Load batting.csv,master.csv
Create Table - temp_batting
Batting.csv to temp_batting
Extract data to  find player with the highest runs for the  year
Player ID to first and last name of the players

create table temp_batting(col_value STRING)
LOAD DATA INPATH '/user/sandbox/Batting.csv' OVERWRITE INTO TABLE temp_batting;
create table batting(player_id STRING,year INT,runs INT);
insert overwrite table batting
SELECT
  regexp_extract(col_value, '^(?:([^,]*)\,?){1}', 1) player_id,
  regexp_extract(col_value, '^(?:([^,]*)\,?){2}', 1) year,
  regexp_extract(col_value, '^(?:([^,]*)\,?){9}', 1) run
from temp_batting;
SELECT year, max(runs) FROM batting GROUP BY year;
SELECT a.year, a.player_id, a.runs from batting a
JOIN (SELECT year, max(runs) runs FROM batting GROUP BY year ) b
ON (a.year = b.year AND a.runs = b.runs) ;

****************************************************************************
Friday, November 07, 2014
7:07 AM

Questions for Hcatalog
How to upload  with multiple Delimiters
For " ",

HiveQL:

			SELECT s07.description, s07.total_emp, s08.total_emp, s07.salary
			FROM
			  sample_07 s07 JOIN 
			  sample_08 s08
			ON ( s07.code = s08.code )
			WHERE
			( s07.total_emp > s08.total_emp
			 AND s07.salary > 100000 )
			SORT BY s07.salary DESC

	Get the data from sample_07
	Create a  table sample09 under sample database
	Uploaded nyse zip file through upload option to /user/sandbox
	After I load table is available in Hcatalog
	Drop table in Hcatalog
	
	Select * from nyse_stocks
	describe nyse_stocks
	select count(*) from nyse_stocks
	select * from nyse_stocks where stock_symbol="IBM"
Pig
	Average of closing stock prices
		Step 1: Create and name the script
		Step 2: Loading the data
		Step 3: Select all records starting with IBM
		Step 4: iterate and average
		Step 5: save the script and execute it
	
	
		a=LOAD 'default.nyse_stocks' USING org.apache.hcatalog.pig.HCatLoader();
		b=FILTER a BY stock_symbol =='IBM' ;
		c=GROUP b ALL;
			#Does this create indexes as per PIG’s syntax?
		d = FOREACH c GENERATE AVG(b.stock_volume);
		DUMP d;
	
	
	Pig Helper templates for the
		 Statements
		 Functions
		 I/O statements
		 HCatLoader() 
		 Python user defined functions.
	Upload UDF option - available

pig -useHcatalog

Library  files can be copied to
	Upload the file to /user/sandbox/slf4j-api-1.7.5.jar.zip
	hadoop fs -get /user/sandbox/slf4j-api-1.7.5.jar.zip
	
LOAD DATA INPATH '/user/hue/query_result.csv' OVERWRITE INTO TABLE `sample.sample_09`